# 训练策略
> pan 4.22 13:12

研究了一下教程。发现，Baseline中给出的训练策略对应于 nnUnet 教程中的 Cascade Unet，并且 fold2 折一折在数据预处理时就已经处理好了。这样我们就只需要分别训练 f0 f1 f3 f4 这四个模型即可。我正在训练 f0 ，一个模型要进行 30000 iters 大概是 12 小时。

## 任务分配
- 潘志清 f0  
- 于嘉烨 f1
- 韦立楠 f3
- 覃仕锋 f4

## 具体操作步骤

### 配置文件修改
找到这个文件夹

![](img/4.jpg)

- 我的已经修改好了，你们只需要根据自己的任务修改配置文件即可。
```yml
data_root: data/

batch_size: 1
iters: 30000

model:
  type: NNUNet
  plan_path: data/preprocessed/nnUNetPlansv2.1_plans_3D.pkl
  stage: 0
  cascade: True

train_dataset:
  type: MSDDataset
  plans_name: nnUNetPlansv2.1_plans_3D.pkl
  dataset_root: /
  result_dir: /
  raw_data_dir: data/raw_data
  decathlon_dir: data/decathlon
  cropped_data_dir: data/cropped
  preprocessed_dir: data/preprocessed
  plan2d: False
  plan3d: True
  num_batches_per_epoch: 250
  fold: 0 # 修改此处 0 1 3 4
  stage: 0
  unpack_data: True
  cascade: True
  mode: train

val_dataset:
  type: MSDDataset
  plans_name: nnUNetPlansv2.1_plans_3D.pkl
  dataset_root: /
  result_dir: /
  raw_data_dir: data/raw_data
  decathlon_dir: data/decathlon
  cropped_data_dir: data/cropped
  preprocessed_dir: data/preprocessed
  num_batches_per_epoch: 50
  fold: 0 # 修改此处 0 1
  stage: 0
  plan2d: False
  plan3d: True
  unpack_data: True
  cascade: True
  mode: val


optimizer:
  type: sgd
  momentum: 0.99
  weight_decay: 0.00003
  use_nesterov: True


lr_scheduler:
  type: PolynomialDecay
  learning_rate: 0.01
  end_lr: 0
  power: 0.9

loss:
  types:
    - type: MultipleLoss
      plan_path: data/preprocessed/nnUNetPlansv2.1_plans_3D.pkl
      stage: 0
      losses:
        - type: DC_and_CE_loss
          do_bg: False
          batch_dice: False
      coef: [1.0]
  coef: [1]
```
将上述代码根据自己的编号修改好然后粘贴进去覆盖掉原来的。注意，配置文件名也要改！ 例如 f0 的配置文件名为 `nnunet_fold0.yml` ，f1 的配置文件名为 `nnunet_fold1.yml` ，以此类推。
### 运行命令调整
``` bash
    # 五折训练脚本
    %cd ~/PaddleSeg/contrib/MedicalSeg/ 
    !python train.py --config ~/configs/nnunet_fold0.yml \
            --log_iters 20 --precision fp16 --nnunet --save_dir output/cascade_lowres/fold0 --save_interval 2000 --use_vdl
    # !python train.py --config ~/configs/nnunet_fold1.yml \
    #         --log_iters 20 --precision fp16 --nnunet --save_dir output/cascade_lowres/fold1 --save_interval 2000 --use_vdl
    # !python train.py --config ~/configs/nnunet_fold3.yml \
    #         --log_iters 20 --precision fp16 --nnunet --save_dir output/cascade_lowres/fold3 --save_interval 2000 --use_vdl
    # !python train.py --config ~/configs/nnunet_fold4.yml \
    #         --log_iters 20 --precision fp16 --nnunet --save_dir output/cascade_lowres/fold4 --save_interval 2000 --use_vdl
```
将上述代码复制并覆盖掉原来的 step5 （第一部分训练 不是第二部分推理）
![](img/3.jpg)
> 然后根据自己分配到的任务，注释掉其他的代码，只运行自己的代码。我是 f0 ，所以只运行第一行代码。以此类推。

### 运行
点击第五步修改后的运行按钮就开始训练了。训练过程中可以在 output/cascade_lowres/fold0/ 文件夹下看到训练日志和模型文件。每20000步保存一次模型参数。大概要等 12 小时左右。建议是第一天先启动一下环境拿 8 点，然后第二天就可以有 16 点了一次性训练好了。

> 后面怎么弄我再看。先这样训练起来。训练好了环境不要销毁，我可能需要把模型联合起来再训练第二阶段。
> 算力不够可以互相点连接刷算力。